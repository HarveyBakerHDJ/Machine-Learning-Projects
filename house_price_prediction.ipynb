{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f336513b-778b-4d0e-ab31-e9d353727362",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3da1d-bb1a-4eca-be0b-dea6f78a80f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d69858-677b-46ab-9e4c-c62b1bcc6758",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ad557-fa89-4a7e-b2f2-23a1dca6535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / reads the csv file and imports to dataframe object 'data'\n",
    "data = pd.read_csv(r'C:\\Users\\44734\\OneDrive\\Desktop\\Python Practice\\Data Sets\\housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f73e8-7c70-4733-90ce-c476f278c726",
   "metadata": {},
   "source": [
    "# Data Modification / Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9bcac2-e764-4b84-a1f2-c2a0288af166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / drops all NaN values from the (df)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd337c-552e-4547-8969-2da60ecdf955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / checks if all NaN / null values are dropped \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ce660a-45f5-4bd9-a4c1-533dbac3a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / imports the test train split class\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e2b35-4118-4273-91ee-fca1bf33ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / assigns the training data into two separate (df)s\n",
    "X = data.drop(['median_house_value'], axis=1) # X is all columns but 'median house value'\n",
    "y = data['median_house_value'] # y is only median house value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6392ad-913d-421c-a2bc-5d9161dd56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / separates into four different datasets using train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25) # test size = 25% of original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe37394-8b4c-41ea-a0cb-1ebfbc544a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / froms training data by joining X_train and y_train\n",
    "train_data = X_train.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35f64b-5c26-4eff-966e-c0ef6e2568d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / displays train_data to check if all is correct\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae6afc-c8aa-4621-99c3-2f49b4040070",
   "metadata": {},
   "source": [
    "# Visualising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a5c651-afa9-4325-9e3f-33bb5a89c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / displays histograms of our data, dropping 'ocean proximity' as it is string values\n",
    "train_data.drop(['ocean_proximity'],axis = 1).hist(figsize=(15, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff3e80b-9c62-4ee3-a884-32532f93f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / \n",
    "plt.figure(figsize= (15, 8))\n",
    "sns.heatmap(train_data.drop(['ocean_proximity'],axis = 1).corr(), annot = True, cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f91958-3bbb-44e5-b4af-07cbb1e4d189",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16af45-510d-4f85-a372-7ce1cbf451a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / transforming each feature to its natural logarithm to normalize the distribution and stabalize variance\n",
    "train_data['total_rooms'] = np.log(train_data['total_rooms']+1) # each feature is transformed, being pulled from the train_data dataframe, 1 is added to each item to avoid taking the (undefined) natural logarithm of 0\n",
    "train_data['total_bedrooms'] = np.log(train_data['total_bedrooms']+1)\n",
    "train_data['population'] = np.log(train_data['population']+1)\n",
    "train_data['households'] = np.log(train_data['households']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae5867-9488-4867-8031-0d0282a2ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / plots new histograms (without the ocean proximity string data) using natural logarithms \n",
    "train_data.drop(['ocean_proximity'],axis = 1).hist(figsize=(15, 8)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9928258-45e0-408d-a345-eab3f2e83c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# // this converts our catagorical data into binary (true / false), and joins it to the training data and also drops the original \n",
    "# / string data from the training data while permantly changing the train_data\n",
    "train_data = train_data.join(pd.get_dummies(train_data.ocean_proximity, dtype=int)).drop(['ocean_proximity'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f3a075-cbf7-4056-a29b-e871dbc039f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# / creates a correlation heatmap between our variabales\n",
    "plt.figure(figsize= (15, 8))\n",
    "sns.heatmap(train_data.corr(), annot=True, cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279161fa-5d09-4442-96f7-b355abb251f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / visualises the median house prices on a map (not scaled), where colour/hue is the median house value\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.scatterplot(x='latitude', y='longitude', data = train_data, hue='median_house_value', palette='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881c8331-c61b-4bf3-8536-c7ec00953820",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16203c-d965-4d9c-9721-2bd3cdf25be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / creates a new column that includes our new feature \n",
    "train_data['bedroom_ratio'] = train_data['total_bedrooms'] / train_data['total_rooms']\n",
    "train_data['household_rooms'] = train_data['total_rooms'] / train_data['households']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c05fb83-ab0b-44a8-af17-f4aa191d17b3",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd95f2cc-f0cf-45fb-9e39-beae186a6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / import model package\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c3023b-c773-41b5-b288-cfaec5479ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / splits our data into training target and input data\n",
    "X_train, y_train = train_data.drop(['median_house_value'], axis = 1), train_data['median_house_value']\n",
    "\n",
    "# / define the type of regression into 'reg' variable\n",
    "reg = LinearRegression()\n",
    "\n",
    "# / fits the data to the model\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b2e82-efdc-43ec-a9fb-de7d5c686f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / create a new test data variable\n",
    "test_data = X_test.join(y_test)\n",
    "\n",
    "# / transforms training data into its natural logarithms \n",
    "test_data['total_rooms'] = np.log(test_data['total_rooms']+1)\n",
    "test_data['total_bedrooms'] = np.log(test_data['total_bedrooms']+1)\n",
    "test_data['population'] = np.log(test_data['population']+1)\n",
    "test_data['households'] = np.log(test_data['households']+1)\n",
    "\n",
    "# / converts the string data [ocean_proximity] in our test_data to binary catagorical values\n",
    "test_data = test_data.join(pd.get_dummies(test_data.ocean_proximity, dtype=int)).drop(['ocean_proximity'], axis = 1)\n",
    "\n",
    "# / creates the new features for test_data as we previously did for training_data \n",
    "test_data['bedroom_ratio'] = test_data['total_bedrooms'] / test_data['total_rooms']\n",
    "test_data['household_rooms'] = test_data['total_rooms'] / test_data['households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882df3e-309c-4346-9914-4626572d5399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / creates target and input test data using the transformed features \n",
    "X_test, y_test = test_data.drop(['median_house_value'], axis = 1), test_data['median_house_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3454932f-ad77-4064-8944-c1356e5bae88",
   "metadata": {},
   "source": [
    "## Model Evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45287ecf-1a60-462d-93d7-9a097675231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# // generates a r^2 score to test how well the model fits our data\n",
    "# / where it incdicates the proportion of the variance in the dependent variable that is predictable from the independent variables\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27bbbac-bed7-47fe-b4b5-546a1ac77455",
   "metadata": {},
   "source": [
    "## Model Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739feebe-2bf3-48e8-9d24-f505985d9e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / create prediction data\n",
    "lr_line = reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b7abd-48c6-4c74-8e79-7ef671a9d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / create plot of highest correlation variable\n",
    "sns.lmplot(x='median_income', y='median_house_value', data=data, scatter_kws={'alpha':0.1})\n",
    "plt.ylim(0, 500000)\n",
    "plt.xlabel('median income')\n",
    "plt.ylabel('median house value')\n",
    "plt.title('median income & median house value regression')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93af5f-e4d1-4ef7-93b2-454bdcaa3de1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
